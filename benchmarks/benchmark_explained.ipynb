{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PQC-TLS Benchmark: Code Explained\n",
    "\n",
    "Dieses Notebook zerlegt das `benchmark.py` Skript in seine Einzelteile. Es erklärt Schritt für Schritt, wie die Messumgebung aufgebaut ist, wie Netzwerkbedingungen simuliert werden und wie die Messungen durchgeführt werden."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Imports & Konfiguration\n",
    "\n",
    "Hier definieren wir die zu testenden Algorithmen (`ALGORITHMS`). Wir unterscheiden zwischen:\n",
    "*   **ML-KEM (Kyber)**: Post-Quanten-Verfahren (z.B. `mlkem512`).\n",
    "*   **P-Curves (ECC)**: Klassische Elliptische Kurven (z.B. `P-256`).\n",
    "*   **Hybride**: Kombination aus beiden (z.B. `p256_mlkem512`).\n",
    "\n",
    "Außerdem legen wir die Test-Szenarien für Latenz (`LATENCIES`) und Paketverlust (`LOSS_RATES`) fest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import sys\n",
    "import subprocess\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Algorithmen Konfiguration\n",
    "ALGORITHMS = [\n",
    "    \"mlkem512\", \"P-256\", \"p256_mlkem512\",\n",
    "    \"mlkem768\", \"P-384\", \"p384_mlkem768\",\n",
    "    \"mlkem1024\", \"P-521\", \"p521_mlkem1024\"\n",
    "]\n",
    "\n",
    "# Metadaten für die Auswertung (Schlüsselgrößen)\n",
    "ALGO_DETAILS = {\n",
    "    \"mlkem512\": {\"pk\": 800, \"ct\": 768, \"label\": \"ML-KEM-512\"},\n",
    "    \"P-256\": {\"pk\": 65, \"ct\": 65, \"label\": \"P-256\"},\n",
    "    \"p256_mlkem512\": {\"pk\": 865, \"ct\": 833, \"label\": \"P-256 + ML-KEM-512\"},\n",
    "    \n",
    "    \"mlkem768\": {\"pk\": 1184, \"ct\": 1088, \"label\": \"ML-KEM-768\"},\n",
    "    \"P-384\": {\"pk\": 97, \"ct\": 97, \"label\": \"P-384\"},\n",
    "    \"p384_mlkem768\": {\"pk\": 1281, \"ct\": 1185, \"label\": \"P-384 + ML-KEM-768\"},\n",
    "    \n",
    "    \"mlkem1024\": {\"pk\": 1568, \"ct\": 1568, \"label\": \"ML-KEM-1024\"},\n",
    "    \"P-521\": {\"pk\": 133, \"ct\": 133, \"label\": \"P-521\"},\n",
    "    \"p521_mlkem1024\": {\"pk\": 1701, \"ct\": 1701, \"label\": \"P-521 + ML-KEM-1024\"},\n",
    "}\n",
    "\n",
    "# Test-Parameter\n",
    "LATENCIES = [0, 50, 100] # Millisekunden (Ping)\n",
    "LOSS_RATES = [0, 5]     # Prozent (Paketverlust)\n",
    "ITERATIONS = 5         # Anzahl der Messungen pro Szenario"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Hilfsfunktion: `run_command`\n",
    "\n",
    "Da wir Docker-Container steuern müssen, führen wir Shell-Befehle aus. Diese Funktion kapselt `subprocess.run` und fängt den Output ab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_command(cmd, shell=True):\n",
    "    # print(f\"Debug: {cmd}\")\n",
    "    result = subprocess.run(cmd, shell=shell, capture_output=True, text=True)\n",
    "    if result.returncode != 0:\n",
    "        # Docker compose kann Warnungen auf stderr ausgeben, auch bei Erfolg.\n",
    "        pass \n",
    "    return result.stdout.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Setup: Testdatei erstellen\n",
    "\n",
    "Um den Datendurchsatz (Transfer) zu messen, benötigen wir eine Datei definierter Größe. Wir erstellen eine 10MB Datei (`10MB.bin`) mit Zufallsdaten und kopieren sie in den Webserver-Container (`server`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_server_file():\n",
    "    print(\"Setting up 10MB test file...\")\n",
    "    filename = \"10MB.bin\"\n",
    "    # Lokale 10MB Datei mit Zufallsdaten erstellen\n",
    "    with open(filename, \"wb\") as f:\n",
    "        f.write(os.urandom(10 * 1024 * 1024))\n",
    "    \n",
    "    # In den Server-Container kopieren\n",
    "    cmd = f\"docker compose cp {filename} server:/opt/nginx/html/testfile\"\n",
    "    run_command(cmd)\n",
    "    \n",
    "    # Lokal aufräumen\n",
    "    os.remove(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Netzwerk-Simulation: `set_network`\n",
    "\n",
    "Das ist das Herzstück der Realismus-Simulation. Wir nutzen das Linux-Tool `tc` (Traffic Control) und `netem` (Network Emulator) im **Client-Container**.\n",
    "\n",
    "Der Befehl `tc qdisc add dev eth0 root netem delay Xms loss Y%` weist den Kernel an, ausgehende Pakete künstlich zu verzögern oder zu verwerfen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_network(latency_ms, loss_percent):\n",
    "    # Zuerst alte Regeln löschen\n",
    "    run_command(\"docker compose exec -T client tc qdisc del dev eth0 root\")\n",
    "    \n",
    "    args = []\n",
    "    if latency_ms > 0:\n",
    "        args.append(f\"delay {latency_ms}ms\")\n",
    "    if loss_percent > 0:\n",
    "        args.append(f\"loss {loss_percent}%\")\n",
    "    \n",
    "    if args:\n",
    "        # Befehl bauen: z.B. \"tc qdisc add dev eth0 root netem delay 50ms loss 5%\"\n",
    "        cmd = f\"docker compose exec -T client tc qdisc add dev eth0 root netem {' '.join(args)}\"\n",
    "        run_command(cmd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Messung: Handshake (`benchmark_handshake`)\n",
    "\n",
    "Hier messen wir exakt, wie lange der **TLS-Handshake** dauert.\n",
    "\n",
    "*   Wir nutzen `curl`.\n",
    "*   `--curves {algo}`: Zwingt `curl`, einen bestimmten Algorithmus (z.B. ML-KEM) zu nutzen.\n",
    "*   ` -w %{time_appconnect}`: Gibt die Zeit vom Start bis zum fertigen Handshake zurück.\n",
    "*   `-o /dev/null`: Wirft den Dateiinhalt weg (uns interessiert nur die Zeit)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def benchmark_handshake(algo, latency):\n",
    "    # URL: Eine kleine Datei (index.html), da wir nur den Handshake wollen.\n",
    "    cmd = f\"docker compose exec -T client curl -k --curves {algo} -o /dev/null -s -w %{{time_appconnect}} https://server:4433/index.html\"\n",
    "    out = run_command(cmd)\n",
    "    try:\n",
    "        val = float(out)\n",
    "        return val\n",
    "    except:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Messung: Transfer (`benchmark_transfer`)\n",
    "\n",
    "Hier messen wir, wie lange der Download der 10MB Datei dauert.\n",
    "\n",
    "*   `time_total`: Die Gesamtzeit (Handshake + Download).\n",
    "*   `time_appconnect`: Die Handshake-Zeit.\n",
    "*   **Rechnung**: `Transfer-Zeit` = `time_total` - `time_appconnect`.\n",
    "\n",
    "So isolieren wir die reine Datengeschwindigkeit von der Handshake-Dauer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def benchmark_transfer(algo, latency):\n",
    "    # URL: Die große 10MB Datei (testfile)\n",
    "    cmd = f\"docker compose exec -T client curl -k --curves {algo} -o /dev/null -s -w %{{time_appconnect}},%{{time_total}} https://server:4433/testfile\"\n",
    "    out = run_command(cmd)\n",
    "    try:\n",
    "        parts = out.split(',')\n",
    "        if len(parts) != 2: return None\n",
    "        t_hs = float(parts[0])\n",
    "        t_total = float(parts[1])\n",
    "        return t_total - t_hs\n",
    "    except:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Visualisierung (`plot_results` & `plot_boxplots`)\n",
    "\n",
    "Diese Funktionen nutzen `matplotlib`, um die gesammelten Daten darzustellen.\n",
    "\n",
    "*   **Bar Plot**: Zeigt die Durchschnittswerte gruppiert nach Netzwerk-Szenario.\n",
    "*   **Box Plot**: Zeigt die Verteilung der Messwerte (Min, Max, Median). Das ist besonders wichtig bei Packet Loss, um Ausreißer zu erkennen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_results(results):\n",
    "    # Unique scenarios (lat, loss)\n",
    "    scenarios = sorted(list(set((r['latency_ms'], r.get('packet_loss_percent', 0)) for r in results)))\n",
    "    algos = sorted(list(set(r['algorithm'] for r in results)))\n",
    "\n",
    "    # Setup data structures\n",
    "    # We want grouped bars. Outer group: Scenario. Inner group: Algo.\n",
    "\n",
    "    x = np.arange(len(scenarios))  # the label locations\n",
    "    width = 0.35  # the width of the bars\n",
    "\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(max(12, len(scenarios)*2), 6))\n",
    "\n",
    "    # Prepare data for easy plotting\n",
    "    # {algo: [val_at_scen0, val_at_scen1]}\n",
    "    hs_data = {algo: [] for algo in algos}\n",
    "    tx_data = {algo: [] for algo in algos}\n",
    "\n",
    "    for algo in algos:\n",
    "        for lat, loss in scenarios:\n",
    "            # Find matching result\n",
    "            res = next((r for r in results if r['latency_ms'] == lat and r.get('packet_loss_percent', 0) == loss and r['algorithm'] == algo), None)\n",
    "            hs_data[algo].append(res['handshake_time_s'] if res else 0)\n",
    "            tx_data[algo].append(res['transfer_time_s'] if res else 0)\n",
    "\n",
    "    # Plot Handshake\n",
    "    multiplier = 0\n",
    "    bar_width = 0.8 / len(algos)\n",
    "\n",
    "    for algo, measurements in hs_data.items():\n",
    "        offset = bar_width * multiplier\n",
    "        rects = ax1.bar(x + offset, measurements, bar_width, label=algo)\n",
    "        multiplier += 1\n",
    "\n",
    "    ax1.set_ylabel('Time (s)')\n",
    "    ax1.set_title('Handshake Time by Network Condition')\n",
    "    ax1.set_xticks(x + bar_width * (len(algos) - 1) / 2)\n",
    "    ax1.set_xticklabels([f\"{lat}ms, {loss}% Loss\" for lat, loss in scenarios], rotation=45, ha='right')\n",
    "    ax1.legend()\n",
    "    # ax1.set_yscale('log') # Optional: log scale if differences are huge\n",
    "\n",
    "    # Plot Transfer\n",
    "    multiplier = 0\n",
    "    for algo, measurements in tx_data.items():\n",
    "        offset = bar_width * multiplier\n",
    "        rects = ax2.bar(x + offset, measurements, bar_width, label=algo)\n",
    "        multiplier += 1\n",
    "\n",
    "    ax2.set_ylabel('Time (s)')\n",
    "    ax2.set_title('Transfer Time (10MB) by Network Condition')\n",
    "    ax2.set_xticks(x + bar_width * (len(algos) - 1) / 2)\n",
    "    ax2.set_xticklabels([f\"{lat}ms, {loss}% Loss\" for lat, loss in scenarios], rotation=45, ha='right')\n",
    "    ax2.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def plot_boxplots(results):\n",
    "    # Unique scenarios (lat, loss)\n",
    "    scenarios = sorted(list(set((r['latency_ms'], r.get('packet_loss_percent', 0)) for r in results)))\n",
    "\n",
    "    # Define groups: (Label, Kyber_Algo, ECDHE_Algo, Hybrid_Algo)\n",
    "    groups = [\n",
    "        (\"Level 1\\n(ML-KEM-512 / P-256)\", \"mlkem512\", \"P-256\", \"p256_mlkem512\"),\n",
    "        (\"Level 3\\n(ML-KEM-768 / P-384)\", \"mlkem768\", \"P-384\", \"p384_mlkem768\"),\n",
    "        (\"Level 5\\n(ML-KEM-1024 / P-521)\", \"mlkem1024\", \"P-521\", \"p521_mlkem1024\")\n",
    "    ]\n",
    "\n",
    "    fig, axes = plt.subplots(len(scenarios), 2, figsize=(16, 8 * len(scenarios)))\n",
    "    if len(scenarios) == 1:\n",
    "        axes = np.expand_dims(axes, axis=0)\n",
    "\n",
    "    for i, (lat, loss) in enumerate(scenarios):\n",
    "        lat_results = {r['algorithm']: r for r in results if r['latency_ms'] == lat and r.get('packet_loss_percent', 0) == loss}\n",
    "\n",
    "        y_locs = np.arange(len(groups))\n",
    "\n",
    "        # Prepare data arrays\n",
    "        k_hs, e_hs, h_hs = [], [], []\n",
    "        k_tx, e_tx, h_tx = [], [], []\n",
    "\n",
    "        for label, k_algo, e_algo, h_algo in groups:\n",
    "            k_res = lat_results.get(k_algo)\n",
    "            e_res = lat_results.get(e_algo)\n",
    "            h_res = lat_results.get(h_algo)\n",
    "\n",
    "            k_hs.append(k_res['handshake_raw'] if k_res else [])\n",
    "            e_hs.append(e_res['handshake_raw'] if e_res else [])\n",
    "            h_hs.append(h_res['handshake_raw'] if h_res else [])\n",
    "\n",
    "            k_tx.append(k_res['transfer_raw'] if k_res else [])\n",
    "            e_tx.append(e_res['transfer_raw'] if e_res else [])\n",
    "            h_tx.append(h_res['transfer_raw'] if h_res else [])\n",
    "\n",
    "        # Plot Helper\n",
    "        def draw_grouped_boxplot(ax, data1, data2, data3, title):\n",
    "            # data1=Kyber, data2=ECDHE, data3=Hybrid\n",
    "\n",
    "            # Box 1 (Kyber) at y - 0.2\n",
    "            bp1 = ax.boxplot(data1, positions=y_locs - 0.2, widths=0.15, vert=False, patch_artist=True)\n",
    "            # Box 2 (ECDHE) at y\n",
    "            bp2 = ax.boxplot(data2, positions=y_locs, widths=0.15, vert=False, patch_artist=True)\n",
    "            # Box 3 (Hybrid) at y + 0.2\n",
    "            bp3 = ax.boxplot(data3, positions=y_locs + 0.2, widths=0.15, vert=False, patch_artist=True)\n",
    "\n",
    "            # Coloring\n",
    "            for patch in bp1['boxes']: patch.set_facecolor('skyblue')     # Kyber\n",
    "            for patch in bp2['boxes']: patch.set_facecolor('lightsalmon') # ECDHE\n",
    "            for patch in bp3['boxes']: patch.set_facecolor('lightgreen')  # Hybrid\n",
    "\n",
    "            ax.set_yticks(y_locs)\n",
    "            ax.set_yticklabels([g[0] for g in groups])\n",
    "            ax.invert_yaxis()\n",
    "            ax.set_title(title)\n",
    "            ax.set_xlabel(\"Time (s)\")\n",
    "\n",
    "            # Legend\n",
    "            ax.legend([bp1[\"boxes\"][0], bp2[\"boxes\"][0], bp3[\"boxes\"][0]],\n",
    "                      ['Kyber/ML-KEM', 'ECDHE', 'Hybrid'], loc='best')\n",
    "\n",
    "        draw_grouped_boxplot(axes[i][0], k_hs, e_hs, h_hs, f\"Handshake Time @ {lat}ms / {loss}% Loss\")\n",
    "        draw_grouped_boxplot(axes[i][1], k_tx, e_tx, h_tx, f\"Transfer Time (10MB) @ {lat}ms / {loss}% Loss\")\n",
    "\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Main Loop (Der Ablauf)\n",
    "\n",
    "Hier wird alles zusammengeführt. Das Skript iteriert über:\n",
    "1.  **Latenzen** (0ms, 50ms, ...)\n",
    "2.  **Verlustraten** (0%, 5%, ...)\n",
    "3.  **Algorithmen** (P-256, ML-KEM-512, ...)\n",
    "\n",
    "Für jede Kombination werden mehrere Messungen durchgeführt und die Ergebnisse gespeichert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Benchmark...\n",
      "Setting up 10MB test file...\n",
      "\n",
      "--- Latency: 0ms, Loss: 0% ---\n",
      "Benchmarking mlkem512... "
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'int' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mTypeError\u001B[39m                                 Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[19]\u001B[39m\u001B[32m, line 45\u001B[39m\n\u001B[32m     42\u001B[39m     plot_results(final_results)\n\u001B[32m     44\u001B[39m \u001B[38;5;66;03m# Zum Ausführen einkommentieren:\u001B[39;00m\n\u001B[32m---> \u001B[39m\u001B[32m45\u001B[39m \u001B[43mrun_benchmark\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[19]\u001B[39m\u001B[32m, line 22\u001B[39m, in \u001B[36mrun_benchmark\u001B[39m\u001B[34m()\u001B[39m\n\u001B[32m     19\u001B[39m benchmark_handshake(algo, lat)\n\u001B[32m     21\u001B[39m \u001B[38;5;66;03m# Messung (nur 2 Iterationen für Demo)\u001B[39;00m\n\u001B[32m---> \u001B[39m\u001B[32m22\u001B[39m \u001B[43m\u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43m_\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mITERATIONS\u001B[49m\u001B[43m:\u001B[49m\n\u001B[32m     23\u001B[39m \u001B[43m    \u001B[49m\u001B[43mhs\u001B[49m\u001B[43m \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[43mbenchmark_handshake\u001B[49m\u001B[43m(\u001B[49m\u001B[43malgo\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlat\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     24\u001B[39m \u001B[43m    \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mhs\u001B[49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mhs_times\u001B[49m\u001B[43m.\u001B[49m\u001B[43mappend\u001B[49m\u001B[43m(\u001B[49m\u001B[43mhs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[31mTypeError\u001B[39m: 'int' object is not iterable"
     ]
    }
   ],
   "source": [
    "def run_benchmark():\n",
    "    print(\"Starting Benchmark...\")\n",
    "    setup_server_file()\n",
    "\n",
    "    final_results = []\n",
    "\n",
    "    for lat in LATENCIES:\n",
    "        for loss in LOSS_RATES:\n",
    "            print(f\"\\n--- Latency: {lat}ms, Loss: {loss}% ---\")\n",
    "            set_network(lat, loss)\n",
    "            for algo in ALGORITHMS:\n",
    "                details = ALGO_DETAILS.get(algo, {\"pk\": \"?\", \"ct\": \"?\", \"label\": algo})\n",
    "                print(f\"Benchmarking {algo} [PK: {details['pk']}B, CT: {details['ct']}B] \", end=\"\", flush=True)\n",
    "\n",
    "                hs_times = []\n",
    "                tx_times = []\n",
    "\n",
    "                # Use a few warmups\n",
    "                benchmark_handshake(algo, lat)\n",
    "\n",
    "                for _ in range(ITERATIONS):\n",
    "                    hs = benchmark_handshake(algo, lat)\n",
    "                    if hs is not None:\n",
    "                        hs_times.append(hs)\n",
    "\n",
    "                    tx = benchmark_transfer(algo, lat)\n",
    "                    if tx is not None:\n",
    "                        tx_times.append(tx)\n",
    "                    print(\".\", end=\"\", flush=True)\n",
    "\n",
    "                avg_hs = sum(hs_times)/len(hs_times) if hs_times else 0\n",
    "                avg_tx = sum(tx_times)/len(tx_times) if tx_times else 0\n",
    "\n",
    "                print(f\" Done. HS: {avg_hs:.4f}s, TX: {avg_tx:.4f}s\")\n",
    "\n",
    "                final_results.append({\n",
    "                    \"latency_ms\": lat,\n",
    "                    \"packet_loss_percent\": loss,\n",
    "                    \"algorithm\": algo,\n",
    "                    \"handshake_time_s\": avg_hs,\n",
    "                    \"transfer_time_s\": avg_tx,\n",
    "                    \"key_details\": ALGO_DETAILS.get(algo, {}),\n",
    "                    \"handshake_raw\": hs_times,\n",
    "                    \"transfer_raw\": tx_times\n",
    "                })\n",
    "\n",
    "    # Cleanup\n",
    "    set_network(0, 0)\n",
    "\n",
    "    # Save Results\n",
    "    json_path = \"results.json\"\n",
    "    with open(json_path, 'w') as f:\n",
    "        json.dump(final_results, f, indent=2)\n",
    "    print(f\"\\nResults saved to {json_path}\")\n",
    "\n",
    "    # Plotting\n",
    "    try:\n",
    "        plot_results(final_results)\n",
    "        plot_boxplots(final_results)\n",
    "    except Exception as e:\n",
    "        print(f\"Plotting failed: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
